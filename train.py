import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_curve, confusion_matrix, ConfusionMatrixDisplay

from cardio_library.preprocessing.transformer import CardioTransformer
from cardio_library.models.logistic_model import LogisticModel
from cardio_library.models.decision_tree_model import DecisionTreeModel
from cardio_library.models.random_forest_model import RandomForestModel
from cardio_library.utils.save_load import save_model, save_transformer
from cardio_library.metrics.evaluation import evaluate_model

from cardio_library.model_selection.grid_search import perform_grid_search



# üîπ 1. –î–µ—Ä–µ–∫—Ç–µ—Ä–¥—ñ –æ“õ—É
data = pd.read_csv("cardio_train.csv", sep=";")

# üîπ 2. –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –∞—Ä“õ—ã–ª—ã X, y –±”©–ª—ñ–ø –∞–ª—É
transformer = CardioTransformer()
transformer.fit(data)
X, y = transformer.transform(data)
column_names = X.columns.tolist()
# üîπ 3. –ú–∞—Å—à—Ç–∞–±—Ç–∞—É
scaler = StandardScaler()
X = scaler.fit_transform(X)

# üîπ 4. Train/Test –±”©–ª—É
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# üîπ 5. –ú–æ–¥–µ–ª—å–¥–µ—Ä–¥—ñ –¥–∞–π—ã–Ω–¥–∞—É
models = {
    "Logistic Regression": LogisticModel(learning_rate=0.01, n_iter=1000, reg_lambda=0.0, class_weight='balanced'),
    "Decision Tree": DecisionTreeModel(max_depth=5, min_samples_split=10),
    "Random Forest": RandomForestModel(n_estimators=100, max_depth=10, min_samples_split=5)
}

# üîπ 6. ”ò—Ä –º–æ–¥–µ–ª—å –±–æ–π—ã–Ω—à–∞ –±–∞“ì–∞–ª–∞—É –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä—ñ–Ω –∂–∏–Ω–∞—É
results = []
roc_curves = {}

for name, model in models.items():
    print(f"\nüìå {name} –º–æ–¥–µ–ª—ñ–Ω –æ“õ—ã—Ç—É –±–∞—Å—Ç–∞–ª–¥—ã...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)

    # –ú–µ—Ç—Ä–∏–∫–∞–ª–∞—Ä–¥—ã –±–∞“ì–∞–ª–∞—É
    metrics = evaluate_model(y_test, y_pred, y_proba)
    metrics["Model"] = name
    results.append(metrics)

    # ROC “õ–∏—Å—ã“ì—ã
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_curves[name] = (fpr, tpr, metrics["roc_auc"])

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(cmap='Blues')
    plt.title(f"{name} ‚Äî “ö–∞—Ç–µ –º–∞—Ç—Ä–∏—Ü–∞—Å—ã")
    plt.grid(False)
    plt.tight_layout()
    plt.show()

# üîπ 7. –ù”ô—Ç–∏–∂–µ–ª–µ—Ä–¥—ñ –∫–µ—Å—Ç–µ–≥–µ –∂–∏–Ω–∞—É
results_df = pd.DataFrame(results)
results_df = results_df[["Model", "accuracy", "precision", "recall", "f1_score", "roc_auc"]]

print("\nüìä –ú–æ–¥–µ–ª—å–¥–µ—Ä–¥—ñ“£ —Å–∞–ª—ã—Å—Ç—ã—Ä–º–∞–ª—ã –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä—ñ:")
print(results_df)

# üîπ 8. ROC “õ–∏—Å—ã“õ—Ç–∞—Ä—ã–Ω –±—ñ—Ä –≥—Ä–∞—Ñ–∏–∫–∫–µ —Å–∞–ª—É
plt.figure(figsize=(8, 6))
for name, (fpr, tpr, roc_auc) in roc_curves.items():
    plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc:.2f})")

plt.plot([0, 1], [0, 1], 'k--', label='–ö–µ–∑–¥–µ–π—Å–æ“õ')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title(' ROC “õ–∏—Å—ã“õ—Ç–∞—Ä—ã–Ω—ã“£ —Å–∞–ª—ã—Å—Ç—ã—Ä–º–∞—Å—ã')
plt.legend(loc="lower right")
plt.grid(True)
plt.tight_layout()
plt.show()

# üîπ 9. –°–æ“£“ì—ã –º–æ–¥–µ–ª—å–¥—ñ —Å–∞“õ—Ç–∞—É
last_model_name = "Random Forest"
save_model(models[last_model_name], f"cardio_library/models/{last_model_name.replace(' ', '_').lower()}.pkl")
save_transformer(transformer, "cardio_library/preprocessing/transformer.pkl")
print(f"\n‚úÖ {last_model_name} –º–æ–¥–µ–ª—ñ –º–µ–Ω —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä —Å”ô—Ç—Ç—ñ —Å–∞“õ—Ç–∞–ª–¥—ã.")

# üîπ 10. cardio –±–∞“ì–∞–Ω—ã–Ω–¥–∞“ì—ã –∫–ª–∞—Å—Å —Ç–µ“£–≥–µ—Ä—ñ–º—ñ
print("\nüì¶ cardio –º”ô–Ω–¥–µ—Ä—ñ–Ω—ñ“£ –∂–∏—ñ–ª—ñ–≥—ñ:")
print(data['cardio'].value_counts())

import pickle

model_preds = {name: model.predict(X_test) for name, model in models.items()}
model_probas = {name: model.predict_proba(X_test) for name, model in models.items()}

with open("model_preds.pkl", "wb") as f:
    pickle.dump(model_preds, f)

with open("model_probas.pkl", "wb") as f:
    pickle.dump(model_probas, f)

with open("y_test.pkl", "wb") as f:
    pickle.dump(y_test, f)

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

# –ú–æ–¥–µ–ª—å
log_model = LogisticRegression(max_iter=1000, class_weight='balanced')

# –ü–∞—Ä–∞–º–µ—Ç—Ä —Ç–æ—Ä—ã
param_grid = {
    'C': [0.01, 0.1, 1.0, 10.0],
    'penalty': ['l2'],
    'solver': ['lbfgs', 'liblinear']
}

# Grid SearchCV
grid_search = GridSearchCV(log_model, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)
grid_search.fit(X_train, y_train)

best_model = grid_search.best_estimator_
best_params = grid_search.best_params_
best_score = grid_search.best_score_

print("üìå –ï“£ “Ø–∑–¥—ñ–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–ª–µ—Ä:", best_params)
print("üîç –ï“£ “Ø–∑–¥—ñ–∫ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω”ô—Ç–∏–∂–µ—Å—ñ:", best_score)

# –°–∞“õ—Ç–∞—É
save_model(best_model, "cardio_library/models/sklearn_logistic_model.pkl")


